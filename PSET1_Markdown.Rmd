---
title: "Harvard Kennedy School - API 201z"  
subtitle: "Problem Set #1"    
author: "Nolin Greene"  
date: "April 18, 2020"  
output: 
  pdf_document: default
  html_document:
    keep_md: yes
always_allow_html: true
---
***

### Preparations: 

#### Operating System & Software Used:
* MacBook Pro (Retina, 13-inch, Late 2013)  
* macOS Catalina 10.15.4  
* RStudio Version 1.2.5003  

#### Options & Packages Loaded:
```{r, loadpackages, message=FALSE}
rm(list=ls())

options(scipen = 999)

library(readxl);library(dplyr);library(ggplot2);library(plotly)
library(tidyr);library(knitr);library(kableExtra);library(stringr)
```


***
## Question #1: Case Study - Pine Street Inn

#### Load Data:

```{r load_data, message=FALSE}
d<-read_excel("Pine Street Inn Length of Stay Data - Solutions.xls", 
              sheet = 1, cell_cols(1:2))

colnames(d)<-c("n","los")
```

#### Analysis:

*1.1:* The mean length of stay at Pine Street Inn is **$`r round(mean(d$los),0)`$ days**. 

*1.2:* The median length of stay at Pine Street Inn is **$`r round(median(d$los),0)`$ days**. 

*1.3:* The maximum length of stay at Pine Street Inn is **$`r max(d$los)`$ days** and the minimum length of stay is **$`r min(d$los)`$ day**. 

*1.4:* The 75th percentile length of stay at Pine Street Inn is **$`r round(quantile(d$los, probs=.75),0)`$ days.**  The 95th and 99th percentiles are **$`r round(quantile(d$los, probs=.90),0)`$ days** and **$`r round(quantile(d$los, probs=.95),0)`$ days** respectively

*1.5:* There are **$`r format(sum(d$los), big.mark = ",")`$ bednights** represented in the dataset.

*1.6:* There are **$`r nrow(d)`$ guests** represented in the dataset.

*1.7* 
```{r, rawdatafortable, include = FALSE}
d%>%
  filter(los<=3) %>%
  summarize(n=n(), bednights=sum(los))

d%>%
  filter(los<=10 & los>3) %>%
  summarize(n=n(), bednights=sum(los))

d%>%
  filter(los<=35 & los>10) %>%
  summarize(n=n(), bednights=sum(los))

d%>%
  filter(los<=150 & los>35) %>%
  summarize(n=n(), bednights=sum(los))

d%>%
  filter(los>150) %>%
  summarize(n=n(), bednights=sum(los))
```



### Summary Statistics for PSI Length of Stay
```{r, echo = F}
Length_of_Stay<-c("3 Days or Less", "4 to 10 Days", "11 to 35 Days", "36 to 150 Days", "151 Days or More")
Number_of_Guests<-c(721, 1177, 1048, 721, 288)
Number_of_Bed_Nights<-c(4973, 7328, 21007, 53832, 84765)
Fraction_of_Guests<-c(round(721/6556,2), round(1177/6556,2), round(1048/6556,2), round(721/6556,2), round(288/6556,2))
Fraction_of_Bed_Nights<-c(round(4973/sum(d$los),2), round(7328/sum(d$los),2), round(21007/sum(d$los),2), round(53832/sum(d$los),2), round(84765/sum(d$los),2))
AvgBedNightsperGuest<-c(round(4973/3322,0),round(7329/1177,0),round(21007/1048,0),round(53832/721,0),round(84765/288,0))
 
one7<-data.frame(Length_of_Stay,Number_of_Guests,Number_of_Bed_Nights,Fraction_of_Guests,Fraction_of_Bed_Nights,AvgBedNightsperGuest, row.names = 1)
one7<-rbind(one7, Total=c(sum(one7$Number_of_Guests),sum(one7$Number_of_Bed_Nights),"", "", "",""))
names_spaced<-c("Number of <br>Guests", "Number of <br>Bed Nights", "Fraction <br>of Guests", "Fraction of <br>Bed Nights","Avg Bed Nights <br> per Guest")
one7<-mutate_all(one7, as.numeric)
kable(one7,
      format.args = list(big.mark = ","),
      row.names = F,
      col.names = names_spaced, 
      escape = F,
      caption = "Guest and Bed Night Statistics by Length of Stay Category") %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```

*1.8:* 
```{r}
d<-d %>%
  mutate(bin = case_when(
      los<4 ~ "3 Days or Less",
      los>3 & los<11 ~ "4 to 10 Days",
      los>10 & los <36 ~ "11 to 35 Days",
      los>35 & los<151 ~"36 to 150 Days",
      los>150 ~ "151 Days or More"),
    bin = factor(bin, levels = c("3 Days or Less","4 to 10 Days","11 to 35 Days",
                 "36 to 150 Days", "151 Days or More")))

count<-group_by(d, bin)%>%
  summarise(n = n(), los=sum(los))

count<-mutate(count,
       Clients = count$n/sum(count$n),
       Bed_Nights = count$los/sum(count$los))

count<-count[c(1,4,5)]

g<-gather(count, stat, percent, -bin)

p<-ggplot(g,aes(x=bin, y=percent, group = stat, color=stat))+
  geom_line()+
  theme(legend.title = element_blank()) +
  labs(x="Length of Stay", y="Percent of Total", title = "Total Clients and Bednights by Length of Stay")+
  scale_x_discrete(labels = function(x) str_wrap(x, width = 8))
```


*1.9:* 

```{r}
ggplot(d, aes(x=los))+
  geom_histogram(colour="black", fill = "slategray", binwidth = 10)+
  labs(x="Length of Stay (days)", y="Number of Guests", title="Distribution of Guests by Length of Stay")
```

*1.9:* Simply by looking at the mean, one might infer that it is common for a PSI guest to spend 3-4 weeks in shelter. However, upon calculating additional statistics (median, IQR, historgram), we see that the distribution of length of stay is heavily right skewed, with a small number of guests having very long stays. This leads me to believe that Pine Street faces a very severe Pareto Principle, with a small number of guests occupying an extreme proportion of the shelter's total bed stays. 


***

## Question #2: State Spending Data

*A.* The total direct expenditure was $3.147tr. The total spent on Elementary and Secondary Education was $565bn, the total spent on Health was $84bn and the total spent on Corrections was $72.6bn.

*B.* The data are organized into columns separated by spaces. There appears to be five columns, with each row separated on a different line. The state code is contained in the row's first two characters (Delaware = "08") and the item code is contained in characters with position 5-7 (Construction for Primary & Secondary Education = "F12"). 

*C.*
This chunk downloads and extracts our zip file, and creates a data frame from it. 
```{r, download & extract file, message=FALSE}
temp <- tempfile()
download.file("http://www2.census.gov/govs/local/11statetypepu.zip",temp)
state_exp <- read.table(unz(temp, "11statetypepu.txt"))
unlink(temp)
```

This chunk cleans and tidys our data. 
```{r cleans & tidys data }
colnames(state_exp)<-c("govtype","itemcode","amount", "cv", "yr")
state_exp$govtype<-formatC(state_exp$govtype, width = 3, format = "d", flag = "0")
state_exp<-transform(state_exp, state = substr(govtype,1,2), gov_level=substr(govtype, 3,3))
state_exp<-filter(state_exp, gov_level == 1)
state_exp<-select(state_exp, -govtype, -yr, -gov_level)
state_exp$amount<-state_exp$amount/1000
```

This chunk creates three clear categories of spend and groups the rows by that spend and each state. 
```{r creates categories & groups rows}
state_exp<-state_exp %>%
  mutate(cat = case_when(
      itemcode=="E32" | itemcode=="F32" | itemcode=="G32" ~ "Health",
      itemcode=="E12" | itemcode=="F12" | itemcode=="G12" ~ "Education",
      itemcode=="E04" | itemcode=="F04" | itemcode=="G04" |
      itemcode=="E05" | itemcode=="F05" | itemcode=="G05" ~ "Corrections"))
state_exp<-filter(state_exp, cat %in% c("Health", "Education", "Corrections"))
state_exp <- state_exp %>%
  group_by(state,cat)%>%
  summarize(sum = sum(amount))
```

The above code found rows whose item codes are related to Health, Education or Corrections and summed all expenditures in the dataset by those groupings. The result is a simple data frame displaying how much was expended across the country for those three categories (in millions). 

*D.* The categories of E32, F32 and G32 represent "Current Operations", Construction" and "Other Capital Outlays" for "other" health expenditures not otherwise captured in other item codes. 

*E.* One reason we need to look at combined state and local expenditures is because different states have different frameworks for allocating governmental responsibilities within policy areas. For example, some states might take on the majority of the financial and administrative burden for maintaining corrections, while other states might cede that authority to the local level. 

#### Adding on State Names
```{r, add statenames, warning=FALSE}
statenames<-read.csv("statenames.csv", colClasses = c(state = "character", names = "character", pop = "numeric"))
state_exp<-left_join(state_exp, statenames, by = "state")
spendclean<-filter(state_exp,state != "00")[,2:5]
```

*F.* The data are now represented in millions. We converted them from thousands to millions by dividing the original value by 1000.

*G*
```{r add per capita statistics}
spendclean<-spendclean %>%
  mutate(per_capita = sum*1000000/pop)
```

*H*
```{r create summary table of per capita statistics, echo = FALSE}
pc_corrections<-filter(spendclean, cat == "Corrections")$per_capita
pc_health<-filter(spendclean, cat == "Health")$per_capita
pc_educ<-filter(spendclean, cat == "Education")$per_capita

sum_stats<-data.frame(Mean = c(mean(pc_health), mean(pc_educ), mean(pc_corrections)),
           StdDev = c(sd(pc_health), sd(pc_educ), sd(pc_corrections)),
           Median = c(median(pc_health), median(pc_educ), median(pc_corrections)),
           IQR = c(IQR(pc_health), IQR(pc_educ), IQR(pc_corrections)), row.names = 
             c("Health", "Education", "Corrections"))

kable(sum_stats,
      format.args = list(big.mark = ","),
      row.names = T,
      digits = 1,
      caption = "Summary Statistics for State Per Capita Spending",
      escape = F) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

*I (i)* The formula for the variance of health spending can be denoted by the following:  

$$
\Large
\begin{aligned}
\sigma^{2} = \frac{\sum\limits_{i=1}^{n} \left(x_{i} - \overline{x}\right)^{2}} {n-1}
\end{aligned}
$$

*I (ii)* The variance is the sum of the squared differences of each observation and the mean, divided by the number of observations minus 1.

*I (iii)* 
```{r calculate variance longform}
x1<-mean(pc_health)
x2<-pc_health-x1
x3<-x2^2

sum(x3)/length(x3)-1
sqrt(sum(x3)/length(x3)-1)
```

*J* 
```{r make first scatterplot of sum spending, echo= FALSE}
spendclean_wide<-pivot_wider(spendclean, names_from = cat, values_from = c("sum", "per_capita"))
ggplot(spendclean_wide, aes(sum_Health, sum_Education))+
  geom_point(col = "slategrey", alpha =0.4)+
  labs(title = "State Spending on Education and Health - Plot 1", subtitle = "Total Spending per State")+xlab("Health Spending")+ylab("Education Spending") +theme_light()

```
The plot shows a strong postiive correlation between total education and health spending. This is to be expeceted because the larger the population of the state, the more they are likely to spend on both education and health. 

```{r make second scatterplot of per capita spending, echo= FALSE}
ggplot(spendclean_wide, aes(per_capita_Health, per_capita_Education))+
  geom_point(col = "slategrey", alpha =0.4)+
  labs(title = "State Spending on Education and Health - Plot 2", subtitle = "Per Capita Spending per State")+xlab("Health Spending")+ylab("Education Spending") +theme_light()

```
TThere is no immediate relationship between per capita Health spending and per capital Education spending (though a few outliers may skew the relationship slightly positive). The plot shows a strong postiive correlation between total education and health spending. This is to be expected though since different states may have different priorities with regards to health and education and may fund them at different levels relative to the size of their populations. 

*K* 
```{r histogram of pc_corrections, echo=F}
ggplot(spendclean_wide, aes(x=per_capita_Corrections))+
  geom_histogram(aes(y=..density..),color = "grey4", fill = "slategrey", bins = 15)+ labs(title = "Histogram of Per Capita Corrections Spending")+xlab("Per Capita Spending")+ylab("Density") +theme_light()
```

*L* 
```{r Adjust Alaska}
spendclean_alaska<-mutate(spendclean_wide, per_capita_Corrections = ifelse(names == "Alaska", 10000, per_capita_Corrections))

sum_stats_alaska<-data.frame(Mean = c(mean(spendclean_alaska$per_capita_Corrections)),
           StdDev = c(sd(spendclean_alaska$per_capita_Corrections)),
           Median = c(median(spendclean_alaska$per_capita_Corrections)),
           IQR = c(IQR(spendclean_alaska$per_capita_Corrections)),
           row.names ="Corrections")

kable(sum_stats_alaska,
      row.names = T,
      digits = 1,
      caption = "Summary Statistics for Per Capita Corrections Spending - Inflated Alaska Example",
      escape = F)%>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

The median and the IQR remain unchanged from the original per capita corrections summary, but the mean and the standard deviation have increased dramatically due to Alaska now being a considerable outlier in the dataset.